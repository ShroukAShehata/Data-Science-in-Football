{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-contrib-python\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/28/db15a674d473959efbed4253471ae27f9e68dcb59f87e5a6ac163df4a027/opencv_contrib_python-4.5.1.48-cp37-cp37m-win_amd64.whl (41.2MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-contrib-python) (1.16.5)\n",
      "Installing collected packages: opencv-contrib-python\n",
      "Successfully installed opencv-contrib-python-4.5.1.48\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install opencv-contrib-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\Desktop\\Career\\Freelance\\1.JPG\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32), array([[    0,     0,   650,   136, 52082],\n",
       "        [    3,     4,   647,   127, 11618],\n",
       "        [  520,     5,     2,     1,     2],\n",
       "        [  308,    18,    36,    31,   800],\n",
       "        [   99,    20,    60,    95,  3838],\n",
       "        [  187,    20,    20,    95,  1454],\n",
       "        [  235,    20,    62,    95,  3879],\n",
       "        [  356,    20,    57,    97,  3642],\n",
       "        [  428,    20,    58,    96,  2995],\n",
       "        [  499,    20,    58,    96,  2826],\n",
       "        [  570,    20,    60,    96,  2884],\n",
       "        [  304,    61,    47,    60,  2277],\n",
       "        [  178,    62,     7,     7,    37],\n",
       "        [  188,    63,     1,     1,     1],\n",
       "        [   46,    84,     9,     8,    65]], dtype=int32), array([[346.58511578,  66.42068277],\n",
       "        [154.28765708,  71.22275779],\n",
       "        [520.5       ,   5.        ],\n",
       "        [325.64375   ,  32.595     ],\n",
       "        [128.60891089,  64.02996352],\n",
       "        [196.76685007,  66.2778542 ],\n",
       "        [265.63109049,  66.74477958],\n",
       "        [384.20400879,  67.82537068],\n",
       "        [458.05943239,  69.66477462],\n",
       "        [531.42108988,  67.30962491],\n",
       "        [604.19764216,  66.83113731],\n",
       "        [327.2687747 ,  90.61660079],\n",
       "        [181.10810811,  64.91891892],\n",
       "        [188.        ,  63.        ],\n",
       "        [ 50.15384615,  87.46153846]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply connected component analysis to the thresholded image\n",
    "output = cv2.connectedComponentsWithStats(thresh, 4, cv2.CV_32S)\n",
    "(numLabels, labels, stats, centroids) = output\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] examining component 1/15 (background)\n",
      "[INFO] examining component 2/15\n",
      "[INFO] examining component 3/15\n",
      "[INFO] examining component 4/15\n",
      "[INFO] examining component 5/15\n",
      "[INFO] examining component 6/15\n",
      "[INFO] examining component 7/15\n",
      "[INFO] examining component 8/15\n",
      "[INFO] examining component 9/15\n",
      "[INFO] examining component 10/15\n",
      "[INFO] examining component 11/15\n",
      "[INFO] examining component 12/15\n",
      "[INFO] examining component 13/15\n",
      "[INFO] examining component 14/15\n",
      "[INFO] examining component 15/15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over the number of unique connected component labels\n",
    "for i in range(0, numLabels):\n",
    "\t# if this is the first component then we examine the\n",
    "\t# *background* (typically we would just ignore this\n",
    "\t# component in our loop)\n",
    "\tif i == 0:\n",
    "\t\ttext = \"examining component {}/{} (background)\".format(\n",
    "\t\t\ti + 1, numLabels)\n",
    "\t# otherwise, we are examining an actual connected component\n",
    "\telse:\n",
    "\t\ttext = \"examining component {}/{}\".format( i + 1, numLabels)\n",
    "\t# print a status message update for the current connected\n",
    "\t# component\n",
    "\tprint(\"[INFO] {}\".format(text))\n",
    "\t# extract the connected component statistics and centroid for\n",
    "\t# the current label\n",
    "\tx = stats[i, cv2.CC_STAT_LEFT]\n",
    "\ty = stats[i, cv2.CC_STAT_TOP]\n",
    "\tw = stats[i, cv2.CC_STAT_WIDTH]\n",
    "\th = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "\tarea = stats[i, cv2.CC_STAT_AREA]\n",
    "\t(cX, cY) = centroids[i]\n",
    "    \n",
    "# clone our original image (so we can draw on it) and then draw\n",
    "# a bounding box surrounding the connected component along with\n",
    "# a circle corresponding to the centroid\n",
    "output = image.copy()\n",
    "cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "cv2.circle(output, (int(cX), int(cY)), 4, (0, 0, 255), -1)\n",
    "    \n",
    "# construct a mask for the current connected component by# finding a pixels in the labels array that have the current\n",
    "# connected component ID\n",
    "componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "# show our output image and connected component mask\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.imshow(\"Connected Component\", componentMask)\n",
    "cv2.waitKey(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image = cv2.imread(r\"C:\\Users\\DELL\\Desktop\\Career\\Freelance\\1.JPG\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "mask = np.zeros(gray.shape, dtype=\"uint8\")\n",
    "    \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, numLabels):\n",
    "\t# extract the connected component statistics for the current\n",
    "\t# label\n",
    "\tx = stats[i, cv2.CC_STAT_LEFT]\n",
    "\ty = stats[i, cv2.CC_STAT_TOP]\n",
    "\tw = stats[i, cv2.CC_STAT_WIDTH]\n",
    "\th = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "\tarea = stats[i, cv2.CC_STAT_AREA]\n",
    "    # ensure the width, height, and area are all neither too small\n",
    "\t# nor too big\n",
    "\tkeepWidth = w > 5 and w < 50\n",
    "\tkeepHeight = h > 45 and h < 65\n",
    "\tkeepArea = area > 500 and area < 1500\n",
    "\t# ensure the connected component we are examining passes all\n",
    "\t# three tests\n",
    "\tif all((keepWidth, keepHeight, keepArea)):\n",
    "\t\t# construct a mask for the current connected component and\n",
    "\t\t# then take the bitwise OR with the mask\n",
    "\t\tprint(\"[INFO] keeping connected component '{}'\".format(i))\n",
    "\t\tcomponentMask = (labels == i).astype(\"uint8\") * 255\n",
    "\t\tmask = cv2.bitwise_or(mask, componentMask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the original input image and the mask for the license plate\n",
    "# characters\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Characters\", mask)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
